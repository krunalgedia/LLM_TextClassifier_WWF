{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75cad1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kbged\\Miniconda3\\envs\\wwf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gradio as gr\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "421adbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_excel('../data/raw/Medienmitteilungen Export DE 20230822.xlsx')\n",
    "df2 = pd.read_csv(\"../data/raw/Medienmitteilungen Export DE 20230822- Kriterien der Konstruktivität updated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20a25679",
   "metadata": {},
   "outputs": [],
   "source": [
    "class process_df():\n",
    "    def __init__(self, df):\n",
    "        assert type(df) ==pd.core.frame.DataFrame, f\"Pandas df required, input dtype: {type(df)}\"\n",
    "        self.df = df\n",
    "        \n",
    "    def skim_cols(self, \n",
    "                  df, \n",
    "                  keep_cols=['Inhalt','Konstruktiv (1= eher konstruktiv   0 = eher nicht konstruktiv '], \n",
    "                  renamed_cols = ['content','label']):\n",
    "        self.df = df.drop(columns=[i for i in list(df.columns) if i not in keep_cols])\n",
    "        self.df.columns = renamed_cols\n",
    "        return self.df\n",
    "    \n",
    "    def clean_df(self, df): \n",
    "        df.dropna(inplace=True)\n",
    "        #df.label = df.label.map({'constructive':1,'not constructive':0})\n",
    "        #df.dropna(inplace=True)\n",
    "        df.reset_index(drop=True)\n",
    "        self.df = df.loc[(df.label==1)|(df.label==0)]\n",
    "        return self.df\n",
    "    \n",
    "    def process_and_split_df(self, df):    \n",
    "        self.df = df.astype({'label':int})\n",
    "        Xy_train, Xy_test, y_train, y_test = train_test_split(self.df, self.df.label, test_size=0.2, stratify=self.df.label, random_state=42)\n",
    "        Xy_train.reset_index(inplace=True, drop=True)\n",
    "        Xy_test.reset_index(inplace=True, drop=True)\n",
    "        Xy_train_series = Xy_train.apply(lambda row: f\"Text: {row[Xy_train.columns[0]]} \\n Class:{row[Xy_train.columns[1]]} \\n \\n\", axis=1)\n",
    "        return Xy_train_series,Xy_test,Xy_train,Xy_test \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48d76041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is mainly for classification with 1/0 label\n",
    "\n",
    "pdf = process_df(df)\n",
    "dfx = pdf.skim_cols(df)\n",
    "dfx = pdf.clean_df(dfx)\n",
    "Xy_train_series,Xy_test,Xy_train,Xy_test = pdf.process_and_split_df(dfx)\n",
    "\n",
    "class1_idx = Xy_train.loc[Xy_train.label==1].index \n",
    "class0_idx = Xy_train.loc[Xy_train.label==0].index\n",
    "\n",
    "#ideal case would be to loop over entire Xy_train_series but can't due to limit on number of input tokens\n",
    "presticker=''\n",
    "for i in np.concatenate([np.random.choice(class1_idx,2),np.random.choice(class0_idx,2)]): \n",
    "    presticker += Xy_train_series[i]\n",
    "presticker += 'Text: '\n",
    "poststicker   = '\\n Class:'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8530b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = process_df(df)\n",
    "df = pdf.skim_cols(df, \n",
    "                   keep_cols = ['Inhalt','Konstruktiv (1= eher konstruktiv   0 = eher nicht konstruktiv ','Hinweis'],\n",
    "                   renamed_cols = ['content','label','reason'])\n",
    "df = pdf.clean_df(df)\n",
    "\n",
    "class presticker_compute():\n",
    "    def __init__(self, presticker, version, df:None, df2:None, label_map:None, question:None):\n",
    "        assert type(presticker)== str, f\"string presticker required, input type: {type(presticker)}\"\n",
    "        assert version in ['v1','v2'], f\"Version should be either v1 or v2\"\n",
    "        self.presticker = presticker\n",
    "        self.version = version\n",
    "        self.df = df\n",
    "        self.df2 = df2\n",
    "        self.label_map = label_map\n",
    "        self.question = question\n",
    "        \n",
    "    def get_presticker(self):\n",
    "        if self.version=='v1':\n",
    "            return self.presticker\n",
    "        if self.version=='v2':\n",
    "            assert type(self.df) ==pd.core.frame.DataFrame, f\"Pandas df required, input dtype: {type(self.df)}\"\n",
    "            assert type(self.df2) ==pd.core.frame.DataFrame, f\"Pandas df required, input dtype: {type(self.df2)}\"\n",
    "            assert type(self.label_map) == dict, f\"Dict required, input dtype: {type(self.label_map)}\"\n",
    "            assert type(self.question) == str, f\"str required, input dtype: {type(self.question)}\"\n",
    "            self.presticker = self.prestick_keypoints(self.df2, self.presticker)\n",
    "            self.presticker = self.prestick_reason(self.df, self.presticker, self.label_map)\n",
    "            self.presticker = self.prestick_question(self.presticker, self.question)\n",
    "            return self.presticker \n",
    "             \n",
    "    def prestick_keypoints(self, df, presticker):\n",
    "        for col in df.columns:\n",
    "            self.presticker += col\n",
    "            self.presticker += '\\n'\n",
    "            self.presticker += df.loc[:,col].str.cat(sep='\\n')\n",
    "            self.presticker += '\\n'\n",
    "        return self.presticker   \n",
    "\n",
    "    def prestick_reason(self, df, presticker, label_map):\n",
    "        for k,v in label_map.items():\n",
    "            self.presticker += v\n",
    "            self.presticker += \"\\n\"\n",
    "            self.presticker += df.loc[df['label']==k,'reason'].str.cat(sep='\\n')\n",
    "            self.presticker += \"\\n\"\n",
    "        return self.presticker    \n",
    "\n",
    "    def prestick_question(self, presticker, question):\n",
    "        self.presticker += \"\\n\"\n",
    "        self.presticker += question\n",
    "        self.presticker += \"\\n\"\n",
    "        return self.presticker            \n",
    "\n",
    "class poststicker_compute():\n",
    "    def __init__(self, poststicker, version:None):\n",
    "        assert type(poststicker)==str, f\"string poststicker required, input type: {type(poststicker)}\"\n",
    "        assert version in ['v1','v2'], f\"Version should be either v1 or v2\"\n",
    "        self.version = version\n",
    "        self.poststicker = poststicker\n",
    "     \n",
    "    def get_poststicker(self):\n",
    "        if self.version=='v1':\n",
    "            return self.poststicker\n",
    "        if self.version=='v2':\n",
    "            self.poststicker = ''\n",
    "            return self.poststicker\n",
    "    \n",
    "    \n",
    "label_map = {\n",
    "    1: \"Für den konstruktiven Text wurden folgende Punkte beachtet:\",\n",
    "    0: \"Bei nicht konstruktivem Text wurden folgende Punkte beachtet:\"\n",
    "}   \n",
    "\n",
    "#question = \"Ist der folgende Text auf der Grundlage dieser Informationen konstruktiv oder nicht? Bitte erklären Sie warum. Bitte verwenden Sie für diese Klassifizierung keine Kontaktdaten:\"    \n",
    "#question = \"Im folgen sollst du diese Informationen nutzen, um Texte mit 0 (destruktiv/ nicht wirklich konsturktiv) oder 1 (konstruktiv) zu bewerten. Gebe außerdem eine Begründung. Bedenke, dass ein negativer aspekt immer zum Label 0 führt und dieser im Text überarbeitet werden sollte. Hier der Text:\"\n",
    "question = \"Im folgenden bist du ein hoch kritischer Analyst, welcher Texte sehr schnell als destruktiv einstuft. Bewerte nun den folgenden Text mit 0 (destruktiv/ nicht wirklich konsturktiv) oder 1 (konstruktiv). Gebe außerdem eine Begründung. Bedenke, dass ein negativer aspekt immer zum Label 0 führt und dieser im Text überarbeitet werden sollte. Hier der text:\"\n",
    "\n",
    "presticker  = presticker_compute('',\"v2\", df, df2, label_map, question).get_presticker()\n",
    "poststicker = poststicker_compute('',\"v2\").get_poststicker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1763412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Öffnen  Konfigurationseinstellungen Zwei kleine Luchse , Heute hat Umweltministerin Simonetta Sommaruga an einer Pressekonferenz in Bern über das Jagdgesetz informiert. Wir möchten Sie darauf hinweisen, dass die breite Nein-Allianz steht und sich ein Parlamentarier-Komitee gebildet hat. Parlamentarier/innen aus allen politischen Lagern, Jäger, Förster, Naturschützer, Tierschutz-Organisationen kämpfen im Interesse von Biber, Luchs, Birkhahn, Wolf und Co. gegen das missratene Jagdgesetz. Nur ein NEIN stoppt das missratene Abschussgesetz. Biber, Graureiher, Luchs und Wolf verdienen unser Engagement. • \\xa0 \\xa0 \\xa0 Seltene Tierarten kommen noch mehr unter Druck. Das Gesetz schwächt den Schutz wildlebender Tiere statt ihn zu stärken. • \\xa0 \\xa0 \\xa0 Biber, Graureiher, Höckerschwan, Luchs, Wolf und andere sind in Gefahr. Der Bundesrat kann sie jederzeit auf die Liste der regulierbaren Arten setzen. Volk oder Parlament haben dazu nichts zu sagen. • \\xa0 \\xa0 \\xa0 Abschüsse geschützter Tiere sind möglich, ohne dass diese je Schäden angerichtet haben. Selbst in Wildtierschutzgebieten wird geschützten Tieren nachgestellt! Weitere Informationen: https://jagdgesetz-nein.ch/ Kontakt: Jonas Schmid, Kommunikationsberater\\xa0WWF Schweiz, jonas.schmid@wwf.ch, 079 241 60 57'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use this in the test_input\n",
    "Xy_test.iloc[10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "181a93a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use this as Test label\n",
    "Xy_test.iloc[10,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "182e41ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in user: history is []\n",
      "in user: user_message is: hey there\n",
      "in bot: history is [['hey there', None]]\n",
      "in bot: messages_history is []\n",
      "in ask_gpt: tmp_messages_history is: [{'role': 'user', 'content': 'I am bosshey there'}]\n",
      "in ask_gpt: messages_history: [{'role': 'user', 'content': 'hey there'}]\n",
      "in bot: final messages_history is [{'role': 'user', 'content': 'hey there'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}]\n",
      "in user: history is [['hey there', 'Hello! How can I assist you today?']]\n",
      "in user: user_message is: you are nice\n",
      "in bot: history is [['hey there', 'Hello! How can I assist you today?'], ['you are nice', None]]\n",
      "in bot: messages_history is [{'role': 'user', 'content': 'hey there'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}]\n",
      "in ask_gpt: tmp_messages_history is: [{'role': 'user', 'content': 'I am bossyou are nice'}]\n",
      "in ask_gpt: messages_history: [{'role': 'user', 'content': 'hey there'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'you are nice'}]\n",
      "in bot: final messages_history is [{'role': 'user', 'content': 'hey there'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'you are nice'}, {'role': 'assistant', 'content': 'Thank you for your kind words! I appreciate your acknowledgement. How can I assist you today as your boss?'}]\n"
     ]
    }
   ],
   "source": [
    "presticker=\"I am boss\"\n",
    "poststicker=''\n",
    "# Set up OpenAI API key\n",
    "# Add your chatGPT keys here\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "system_message = {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    state = gr.State([])\n",
    "\n",
    "    def user(user_message, history):\n",
    "        print('in user: history is',history)\n",
    "        print('in user: user_message is:',user_message)\n",
    "        return \"\", history + [[user_message, None]]\n",
    "\n",
    "    def bot(history, messages_history):\n",
    "        print('in bot: history is',history)\n",
    "        print('in bot: messages_history is',messages_history)\n",
    "        user_message = history[-1][0]\n",
    "        bot_message, messages_history = ask_gpt(user_message, messages_history)\n",
    "        #bot_message is the reply to the user_message\n",
    "        messages_history += [{\"role\": \"assistant\", \"content\": bot_message}]\n",
    "        history[-1][1] = bot_message\n",
    "        time.sleep(1)\n",
    "        print('in bot: final messages_history is',messages_history)\n",
    "        return history, messages_history\n",
    "\n",
    "    def ask_gpt(message, messages_history):\n",
    "        message_history = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                           {\"role\": \"user\", \"content\": presticker+message+poststicker}] \n",
    "        #messages_history += [{\"role\": \"user\", \"content\": message}]\n",
    "        #print('in ask_gpt: tmp_messages_history is:',tmp_message_history)\n",
    "        print('in ask_gpt: messages_history:', messages_history)\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-16k\",\n",
    "            messages=message_history\n",
    "        )\n",
    "        #print('in ask_gpt: response is ',response['choices'][0]['message']['content'])\n",
    "        return response['choices'][0]['message']['content'], messages_history\n",
    "\n",
    "    def init_history(messages_history):\n",
    "        messages_history = []\n",
    "        messages_history += [system_message]\n",
    "        print('init_history: ',messages_history)\n",
    "        return messages_history\n",
    "    \n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, [chatbot, state], [chatbot, state]\n",
    "    )\n",
    "\n",
    "    clear.click(lambda: None, None, chatbot, queue=False).success(init_history, [state], [state])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d5d81ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up OpenAI API key\n",
    "# Add your chatGPT keys here\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "system_message = {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    state = gr.State([])\n",
    "\n",
    "    def user(user_message, history):\n",
    "        #print('in user: history is',history)\n",
    "        #print('in user: user_message is:',user_message)\n",
    "        return \"\", history + [[user_message, None]]\n",
    "\n",
    "    def bot(history, messages_history):\n",
    "        #print('in bot: history is',history)\n",
    "        user_message = history[-1][0]\n",
    "        bot_message, messages_history = ask_gpt(user_message, messages_history)\n",
    "        #bot_message is the reply to the user_message\n",
    "        messages_history += [{\"role\": \"assistant\", \"content\": bot_message}]\n",
    "        history[-1][1] = bot_message\n",
    "        time.sleep(1)\n",
    "        return history, messages_history\n",
    "\n",
    "    def ask_gpt(message, messages_history):\n",
    "        tmp_message_history = [{\"role\": \"user\", \"content\": presticker+message+poststicker}] \n",
    "        messages_history += [{\"role\": \"user\", \"content\": message}]\n",
    "        #print('in ask_gpt: tmp_messages_history is:',tmp_message_history)\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-16k\",\n",
    "            messages=tmp_message_history\n",
    "        )\n",
    "        #print('in ask_gpt: response is ',response['choices'][0]['message']['content'])\n",
    "        return response['choices'][0]['message']['content'], messages_history\n",
    "\n",
    "    def init_history(messages_history):\n",
    "        messages_history = []\n",
    "        messages_history += [system_message]\n",
    "        return messages_history\n",
    "    \n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, [chatbot, state], [chatbot, state]\n",
    "    )\n",
    "\n",
    "    clear.click(lambda: None, None, chatbot, queue=False).success(init_history, [state], [state])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2800c9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 23:49:44.649 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\kbged\\Miniconda3\\envs\\wwf\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2023-11-19 23:49:44.650 Session state does not function when running a script without `streamlit run`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import streamlit as st\n",
    "import time\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "system_message = {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "\n",
    "st.title(\"Chatbot Demo\")\n",
    "\n",
    "msg = st.text_input(\"User Message:\")\n",
    "clear_button = st.button(\"Clear\")\n",
    "\n",
    "state = st.session_state.get(\"state\", [])\n",
    "\n",
    "if clear_button:\n",
    "    state = []\n",
    "    st.session_state.state = state\n",
    "\n",
    "def user(user_message, history):\n",
    "    return \"\", history + [[user_message, None]]\n",
    "\n",
    "def bot(history, messages_history):\n",
    "    user_message = history[-1][0]\n",
    "    bot_message, messages_history = ask_gpt(user_message, messages_history)\n",
    "    messages_history += [{\"role\": \"assistant\", \"content\": bot_message}]\n",
    "    history[-1][1] = bot_message\n",
    "    time.sleep(1)\n",
    "    return history, messages_history\n",
    "\n",
    "def ask_gpt(message, messages_history):\n",
    "    tmp_message_history = [{\"role\": \"user\", \"content\": message}]\n",
    "    messages_history += [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",\n",
    "        messages=tmp_message_history\n",
    "    )\n",
    "    return response['choices'][0]['message']['content'], messages_history\n",
    "\n",
    "def init_history(messages_history):\n",
    "    messages_history = []\n",
    "    messages_history += [system_message]\n",
    "    return messages_history\n",
    "\n",
    "if msg:\n",
    "    state, _ = user(msg, state)\n",
    "    state, _ = bot([msg, state], [msg, state])\n",
    "\n",
    "for h in state:\n",
    "    if h[1]:\n",
    "        st.text(f\"User: {h[0]}\")\n",
    "        st.text(f\"Assistant: {h[1]}\")\n",
    "    else:\n",
    "        st.text(f\"User: {h[0]}\")\n",
    "\n",
    "st.text(\"Assistant: ...\")  # To show that the assistant is typing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "321baa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 00:25:28.847 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\kbged\\Miniconda3\\envs\\wwf\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "st.header('WWF feedback center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c088cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run C:\\Users\\kbged\\Miniconda3\\envs\\wwf\\lib\\site-packages\\ipykernel_launcher.py\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd44d737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook WWFtextclassification.ipynb to python\n",
      "[NbConvertApp] Writing 16138 bytes to WWFtextclassification.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to python WWFtextclassification.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c590116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Obtaining dependency information for streamlit from https://files.pythonhosted.org/packages/9d/9f/09fe6469e891031596872bd50bff90d47bea5c32d426235714cf24662740/streamlit-1.28.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading streamlit-1.28.2-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from streamlit) (5.1.2)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
      "  Obtaining dependency information for blinker<2,>=1.0.0 from https://files.pythonhosted.org/packages/fa/2a/7f3714cbc6356a0efec525ce7a0613d581072ed6eb53eb7b9754f33db807/blinker-1.7.0-py3-none-any.whl.metadata\n",
      "  Downloading blinker-1.7.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit)\n",
      "  Obtaining dependency information for cachetools<6,>=4.0 from https://files.pythonhosted.org/packages/a2/91/2d843adb9fbd911e0da45fbf6f18ca89d07a087c3daa23e955584f90ebf4/cachetools-5.3.2-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from streamlit) (6.8.0)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from streamlit) (1.26.0)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from streamlit) (2.0.3)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from streamlit) (10.0.1)\n",
      "Collecting protobuf<5,>=3.20 (from streamlit)\n",
      "  Obtaining dependency information for protobuf<5,>=3.20 from https://files.pythonhosted.org/packages/fe/6b/7f177e8d6fe4caa14f4065433af9f879d4fab84f0d17dcba7b407f6bd808/protobuf-4.25.1-cp310-abi3-win_amd64.whl.metadata\n",
      "  Downloading protobuf-4.25.1-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting pyarrow>=6.0 (from streamlit)\n",
      "  Obtaining dependency information for pyarrow>=6.0 from https://files.pythonhosted.org/packages/7f/ab/2c69e9ac0a7629e0787fc1bf8dbe9064c6de814077810e62311f564863a6/pyarrow-14.0.1-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading pyarrow-14.0.1-cp310-cp310-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from streamlit) (13.6.0)\n",
      "Collecting tenacity<9,>=8.1.0 (from streamlit)\n",
      "  Obtaining dependency information for tenacity<9,>=8.1.0 from https://files.pythonhosted.org/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl.metadata\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from streamlit) (4.8.0)\n",
      "Collecting tzlocal<6,>=1.1 (from streamlit)\n",
      "  Obtaining dependency information for tzlocal<6,>=1.1 from https://files.pythonhosted.org/packages/97/3f/c4c51c55ff8487f2e6d0e618dba917e3c3ee2caae6cf0fbb59c9b1876f2e/tzlocal-5.2-py3-none-any.whl.metadata\n",
      "  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting validators<1,>=0.2 (from streamlit)\n",
      "  Obtaining dependency information for validators<1,>=0.2 from https://files.pythonhosted.org/packages/3a/0c/785d317eea99c3739821718f118c70537639aa43f96bfa1d83a71f68eaf6/validators-0.22.0-py3-none-any.whl.metadata\n",
      "  Downloading validators-0.22.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Obtaining dependency information for gitpython!=3.1.19,<4,>=3.0.7 from https://files.pythonhosted.org/packages/8d/c4/82b858fb6483dfb5e338123c154d19c043305b01726a67d89532b8f8f01b/GitPython-3.1.40-py3-none-any.whl.metadata\n",
      "  Downloading GitPython-3.1.40-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
      "     ---------------------------------------- 0.0/4.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.1/4.8 MB 1.7 MB/s eta 0:00:03\n",
      "     - -------------------------------------- 0.2/4.8 MB 2.3 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 0.4/4.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 0.7/4.8 MB 3.3 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 0.9/4.8 MB 3.3 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 1.2/4.8 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 1.4/4.8 MB 3.8 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 1.8/4.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 2.1/4.8 MB 4.1 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 2.5/4.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 2.7/4.8 MB 4.5 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 3.1/4.8 MB 4.6 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 3.4/4.8 MB 4.8 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 3.8/4.8 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 4.1/4.8 MB 5.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 4.4/4.8 MB 5.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  4.8/4.8 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.8/4.8 MB 5.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from streamlit) (6.2)\n",
      "Collecting watchdog>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-3.0.0-py3-none-win_amd64.whl (82 kB)\n",
      "     ---------------------------------------- 0.0/82.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 82.0/82.0 kB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.17.3)\n",
      "Requirement already satisfied: toolz in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Obtaining dependency information for gitdb<5,>=4.0.1 from https://files.pythonhosted.org/packages/fd/5b/8f0c4a5bb9fd491c277c21eff7ccae71b47d43c4446c9d0c6cff2fe8c2c4/gitdb-4.0.11-py3-none-any.whl.metadata\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Obtaining dependency information for smmap<6,>=3.0.1 from https://files.pythonhosted.org/packages/a7/a5/10f97f73544edcdef54409f1d839f6049a0d79df68adbc1ceb24d1aaca42/smmap-5.0.1-py3-none-any.whl.metadata\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\kbged\\miniconda3\\envs\\wwf\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.0)\n",
      "Downloading streamlit-1.28.2-py2.py3-none-any.whl (8.4 MB)\n",
      "   ---------------------------------------- 0.0/8.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.6/8.4 MB 12.0 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.1/8.4 MB 10.1 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.6/8.4 MB 9.2 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.0/8.4 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.6/8.4 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.9/8.4 MB 9.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.4/8.4 MB 8.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.7/8.4 MB 8.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.1/8.4 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.7/8.4 MB 8.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.1/8.4 MB 8.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.6/8.4 MB 8.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.9/8.4 MB 8.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.5/8.4 MB 8.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.6/8.4 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.2/8.4 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.0/8.4 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.2/8.4 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.4/8.4 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.4/8.4 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading blinker-1.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
      "   ---------------------------------------- 0.0/190.6 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 112.6/190.6 kB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 190.6/190.6 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading protobuf-4.25.1-cp310-abi3-win_amd64.whl (413 kB)\n",
      "   ---------------------------------------- 0.0/413.4 kB ? eta -:--:--\n",
      "   --------------------------------------  409.6/413.4 kB 12.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 413.4/413.4 kB 6.5 MB/s eta 0:00:00\n",
      "Downloading pyarrow-14.0.1-cp310-cp310-win_amd64.whl (24.6 MB)\n",
      "   ---------------------------------------- 0.0/24.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/24.6 MB 5.3 MB/s eta 0:00:05\n",
      "   ---------------------------------------- 0.2/24.6 MB 2.4 MB/s eta 0:00:11\n",
      "   ---------------------------------------- 0.2/24.6 MB 1.6 MB/s eta 0:00:16\n",
      "    --------------------------------------- 0.4/24.6 MB 2.1 MB/s eta 0:00:12\n",
      "    --------------------------------------- 0.6/24.6 MB 2.5 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.9/24.6 MB 2.9 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.0/24.6 MB 2.9 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.2/24.6 MB 3.1 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 1.6/24.6 MB 3.6 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 1.8/24.6 MB 3.6 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 2.3/24.6 MB 4.2 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 2.7/24.6 MB 4.6 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.4/24.6 MB 5.1 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 3.8/24.6 MB 5.3 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 4.3/24.6 MB 5.6 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 4.4/24.6 MB 5.3 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 4.8/24.6 MB 5.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.1/24.6 MB 5.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.3/24.6 MB 5.3 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 5.6/24.6 MB 5.3 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 5.8/24.6 MB 5.1 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.0/24.6 MB 5.1 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 6.4/24.6 MB 5.1 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 6.6/24.6 MB 5.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 6.8/24.6 MB 4.9 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 7.0/24.6 MB 4.9 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 7.4/24.6 MB 5.0 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 7.7/24.6 MB 5.0 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 8.2/24.6 MB 5.2 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 8.5/24.6 MB 5.2 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 8.9/24.6 MB 5.3 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 9.0/24.6 MB 5.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 9.1/24.6 MB 5.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 9.1/24.6 MB 5.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 9.1/24.6 MB 5.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 9.1/24.6 MB 5.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 9.1/24.6 MB 4.6 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 9.3/24.6 MB 4.5 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 9.5/24.6 MB 4.5 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 9.7/24.6 MB 4.4 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 10.3/24.6 MB 4.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 11.0/24.6 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.4/24.6 MB 5.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.6/24.6 MB 5.2 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 12.2/24.6 MB 5.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 12.9/24.6 MB 5.3 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 13.3/24.6 MB 5.3 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 13.7/24.6 MB 5.3 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 13.9/24.6 MB 5.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 14.4/24.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 14.7/24.6 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 14.9/24.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 14.9/24.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 14.9/24.6 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 15.0/24.6 MB 4.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 15.0/24.6 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 15.1/24.6 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 15.1/24.6 MB 4.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 15.1/24.6 MB 4.5 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.5/24.6 MB 4.5 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.9/24.6 MB 4.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.0/24.6 MB 4.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.1/24.6 MB 4.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.1/24.6 MB 4.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.2/24.6 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.2/24.6 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.3/24.6 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.4/24.6 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.4/24.6 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.4/24.6 MB 4.0 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 16.4/24.6 MB 3.9 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 16.5/24.6 MB 3.9 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 16.5/24.6 MB 3.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 16.5/24.6 MB 3.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 16.7/24.6 MB 3.7 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 16.8/24.6 MB 3.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 16.8/24.6 MB 3.7 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 16.9/24.6 MB 3.6 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 16.9/24.6 MB 3.6 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 16.9/24.6 MB 3.5 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 16.9/24.6 MB 3.4 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 17.0/24.6 MB 3.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 17.6/24.6 MB 3.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 17.8/24.6 MB 3.4 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 18.0/24.6 MB 3.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.1/24.6 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.4/24.6 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.8/24.6 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.3/24.6 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 19.9/24.6 MB 3.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.3/24.6 MB 3.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.5/24.6 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.0/24.6 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.3/24.6 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.7/24.6 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.8/24.6 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.2/24.6 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.5/24.6 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.2/24.6 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.7/24.6 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.7/24.6 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.9/24.6 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.3/24.6 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.6/24.6 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.6/24.6 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.6/24.6 MB 3.4 MB/s eta 0:00:00\n",
      "Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.7/62.7 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: watchdog, validators, tzlocal, toml, tenacity, smmap, pyarrow, protobuf, cachetools, blinker, pydeck, gitdb, gitpython, streamlit\n",
      "Successfully installed blinker-1.7.0 cachetools-5.3.2 gitdb-4.0.11 gitpython-3.1.40 protobuf-4.25.1 pyarrow-14.0.1 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.28.2 tenacity-8.2.3 toml-0.10.2 tzlocal-5.2 validators-0.22.0 watchdog-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045e379b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee03593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6efae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398ddf00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2726609f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a6056c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57617a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't run after this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5dda1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Konstruktiv  bzw. lösungsorientiert ist der Text, wenn beinhaltet: \\nDas Problem wird verständlich erklärt\\nWie geht es jetzt weiter?\\nWerden Lösungen präsentiert?\\nWer arbeitet an den Lösungen?\\nWie wirken die Lösungen?\\nMethode des Lösungsansatzes\\nWas sind echte Lösungen, was sind Scheinlösungen?\\nFaktenbasierte Argumentation\\nBelege für die Lösungen\\nist der Lösungsansatz skalierbar? \\nRisiken des Lösungsansatzes, Grenzen und Nebenwirkungen des Lösungsansatzes\\nEr berschreibt die Wirklichkeit\\nEr ist nicht wertend. \\nKontext wird erschlossen, Einordnung gemacht, Entwicklung aufgezeigt\\nZukunftsperspektiven werden aufgezeigt\\nzeigen ein komplettes Bild der Wirklichkeit\\nErfolgsaussichten werden analysiert\\nzum Denken anregen, \\nEs wird auf komplexität des Problems eingegangen\\nzeigt er Möglichkeiten der Selbstwirksamkeit auf\\nFördern Dialog\\nsind moderierend\\nEnthält Tipps\\nEnthält Beispiele aus dem Alltag\\nBerichtet von zivilgesellschaftlichem Engagement, von Menschen, die Mut machen und andere inspirieren\\nFortschrittsbericht enthält\\nschafft Nähe (Persönliche Geschichte, Leser-Touchpoint)\\nEntlarft mythen\\nMacht Lust zu Handeln\\nKommunikation auf Augenhöhe\\nWas macht Mut, inspiriert\\nNicht konstruktiv bzw. nicht lösungsorientiert ist der Text wenn er :\\nÜberbetonung der Krise (im Verhältnis zu den Lösungen)\\nMoralisierung\\nDrohungen\\nWorte wie müssen, fordern, zwingend, immer, nie,  verzicht, \\nAngst macht\\nPanik macht.\\nSensationsgeil ist\\nnur die News betont\\nNur Alarm schlagen will\\nNur Konflikte und Klüfte aufzeigt\\nNur Schwarz weiss ist.\\nGut gegen Schlecht \\nzynisch ist\\nPopulistisch: simple Parolen als Retter vor der Gefahr\\npolarisiert\\nfake news\\nso starke Vereinfachung, dass die Realität nicht mehr abgebildet wird\\n5 vor 12 Kommunikation: bspw Wenn wir jetzt nicht, dann… // Letzte Chance! // Heute, weil morgen ist es zu spät / Nur du kannst noch helfen // einzige Chance //  \\nSchreckensszenarien\\nFalsche Zahlen\\nSkanalisierung durch Einzelereignisse\\nLügen\\nVerallgemeinerungen\\nKommunikation von \"oben herab\", elitäre Sprache\\nBesserwissertum\\nBeschreibt einen Zustand ohne Kontext, ohne Einordnung, Ohne Zukunftsblick\\nFür den konstruktiven Text wurden folgende Punkte beachtet:\\nBlickt in die Zukunft, zeigt Lösungen auf (andere Länder machen es so), bietet eine Perspektive, zeigt den Kontext auf, ordnet ein (wenn wir weiterfahren wie bisher, schaffen wir es nicht), bringt Fakten ein, hat einen positiven Grundtenor.\\nDas Problem wird (knapp) erklärt, der Kontext wird erschlossen, Einordnung gemacht, Entwicklung aufgezeigt, Lösungsvorschlag gemacht (Dialogart), Konsequenzen aufgezeigt, weitere Infos verlinkt, Kontakt für die COP23 offeriert.\\nsehr komplex, fachlich, kaum verständlich, er zeigt Lösungsansatz auf, sie müssen mehr tun, können es aber auch \\nSehr neutral, deskriptiv, IST-Zustand\\nReine Vollzugsmeldung, Rein deskriptiv\\nKlingt eher positiv, auch wenn es am Anfang noch alles sehr neutral gehalten wird: Auflistung von wer an der Earth Hour teilnehmen wird. \\nBietet Lösungen an, beschreibt Wirklichkeit, \\nIm Trend konstruktiv und positiv, gibt Hoffnung, präsentiert die Gegenwart und blickt hoffnungsvoll in die Zukunft, zeigt unsere  Verantwortung, appelliert an alle Interessengruppen, begeistert für die Naturvielfalt. Skizziert grob Lösungansätze, allerdings etwas eindimensional in der Grundaussage\\nErfolgsmeldung in Sachen Artenschutz, positive Neuigkeit, Einordnung eines Ereignisses in einen grösseren Kontext, blickt in die Zukunft, zeigt Konsequenzen und Folgen der Massnahme auf, zeigt die Lösung, viele Hintergrundinformationen\\nPositive Mitteilung in Sachen Palmöl, zeigt im Detail die positven Folgen eines Entscheides auf, stellt den Kontext her (wer profitiert vom besseren Standard), präsentiert weitere nötige Schritte für die Zukunft (konstruktive Lösungansätze), macht differenziert klar, warum die Verschärfung  nicht genügend weit geht.\\nerklärt anschaulich, was der Overshoot Day ist. Zeigt die Rolle der Schweiz im europäischen Vergleich, präsentiert ein konkretes Beispiele (CO2) , bietet konkrete Tipps mit einem Onlinetool  (Footprint-Rechner), bringt  Hintergrundinfos, gibt Hoffnung, da sie nicht nur die Zahl vermeldet, sondern auch zeigt, was wir tun können, um die Situation zu verbessern.\\neher konstruktive, differenzierte und ausführliche Bewertung der Jagdgesetzrevision, zum Teil etwas schwer verständlich. Stellt den Kontext her, illustriert transparent, was zur ablehnenden Haltung der Verbände geführt hat, Lösungansatz wird ganz am Schluss skizziert.\\nMacht Lust zum Handeln, Problem wird verständlich erklärt, enthält Beispiele aus dem Alltag\\nTitel ist voller Power. Energiereiche MM. Man stellt klar, dass man die Situation in der Hand hat und verändern wird.\\nGute Nachricht, auch wenn sie allgemein sehr neutral gehalten wird. Ist aber eine Good News.\\nFachlich komplex, unverständlich für den Laien, aber konstruktiv: im Sinne von \"jetzt schreiten wir zur Tat!\"\\nLösungen, macht Lust zum Handeln\\nKonstruktiv, auch wenn ich mehr Vorschläge erwartet hätte (eine Aufzählung oder so).\\nSehr schöne MM mit konstruktiven Ideen.\\nzeigt den Kontext auf, präsentiert Unternehmen konkrete Empfehlungen, ist in der Wortwahl  konstruktiv (Chance, begrüsst, stark ansteigendes Interesse, Verbesserung der Klimabilanz, Vorreiter für mehr Klimaschutz), Hinweis auf Unterlagen, lösungsorientiert, blickt in die Zukunft, wirkt motivierend\\nViele Punkte werden aufgezählt um konstruktiv eine Lösung zu finden.\\n Es werden viele Vorschläge gemacht, wie das neue Gesetz aussehen sollte und was noch fehlt. Auch wenn das Thema negativ ist, werden Möglichkeiten angeboten.\\npositiver Grundtenor, kondoliert zum Tod von Prinz Pilip und stellt das Leben des royalen Umweltschützers vor \\ngerade noch knapp konstruktiv, weil es die schlechten Zahlen der Schweiz nicht bloss verurteilt, sondern den Kontext herstellt (Vergleich mit Resteuropa) und auch die Lösung aufzeigt, was man in Zukunft tun muss, um die Klimaschutzziele zu erreichen.\\nZeigt die Lösungsansätze des WWF auf\\nLösungsansätze werden aufgezeigt. \\nDie MM stellt die Gräünde dar für Food Waste, macht konkrete Lösungsvorschläge, verweist auch auf den Aktionplan des Bundes, wirkt in der Tonalität nicht grimmig und besserwisserisch, sondern witzig frisch (Entsorge den Schönheistwahn, nicht Obst und Gemüse, Auf den Teller statt in die Tonne), richtet sich an alle - Konsumenten, politische Behörden, Retailer, Produzenten. \\neher konstruktiv, für den Laien in Titel und Einstieg komplett unverständlich, dann wird der Kontext zu Cites und Tropäenjagd aber breit dargestellt und Positionspapiere verlinkt.\\nkonstuktive Mitteilung, der über die Partnerschaft mit dem IKRK informiert und aufzeigt, welche Chancen sich mit dieser Partnerschaft bieten und wie Mensch und Umwelt in Zukunft davon profitieren können.l\\nNahe bei den Leuten, zeigt Möglichkeiten der Selbstwirksamkeit auf, berichtet von zivilgesellschaftlichem Engagement, von Menschen, die Mut machen und andere inspirieren, Macht Lust auf handeln\\nMacht Mut, lösungsorientiert\\n Auch wenn die Studie beweisst, wie schlecht das Produkt ist. \\ndifferenzierte Darstellung, warum die Umweltverbände auf ein Referendumg gegen das neue JSG verzichten. Zeigt den Kontext auf, ist in der Tonalität äusserst sachlich. Zeigt transparent auf, wie sich die Verbände engagieren werden, und dass sie ein Gesetz mittragen, das sie im Kern nicht begrüssen. Nimmt alle Betroffene in de Pflicht, schaut nach vorn. Ist ein versöhnlicher Beitrag in einem polarisierten Konflikt.\\ninformiert über ein Online-Tool, das Unternehmen erlaubt, selbstständig eine eigene Risikoabschätzung  vorzunehmen. Der BRF wird ausführlich erklärt und seine Vorzüge dargestellt - eine echter Push für besseres Wirtschaften. Lösungsorientiert, motiviert zur Prüfung des eigenen Handelns, da das Tool niederschwellig konzipiert ist.\\nAus dem Titel heraus ist aber nicht klar, ob es eine gute Sache ist oder nicht. Der Text ist eher konstruktiv, auch wenn etwas soft gehalten.\\nBei nicht konstruktivem Text wurden folgende Punkte beachtet:\\nZiemlich eindimensional: Der Aktionsplan Biodiv.  wird deutlich kritisiert (bereits im Titel), er sei zahnlos, reiche bei weitem nicht aus und komme viel zu spät. Immerhin wird dem Aktionplan des Bundes eine Gegenvariante entgegengestellt, die in der MM allerdings nur verlinkt ist.\\nWir weisen darauf hin dass die Schweiz eine Chance verpasst hat und verwenden das Wort \"passiv\" öfter. Titel weist schon darauf hin.\\nCH-Finanzmarkt verliert Anschluss. Auch hier eher negative Aussagen: verliert, geht zurück. Am Ende aber gibt es eine Liste von Sachen die man machen kann, um die Situation zu ändern. Im Titel ist es schon negativ.\\nEarth-Overshoot-Day. Optimistiche Punkte fehlen. Man weisst mit einen Link auf Klimatipps.Titel schon negativ.\\nSchon im Titel wird klar, dass es eine Bad News ist, Der ganze Text ist eher nicht konstruktiv.\\nSchon im Titel wird die schlechte Nachricht gegeben. Im Text sind keine konstruktiven Aspekte. \\nwirkt alarmistisch, drei Expert:innen-Zitate mit pessimistischer Einschätzung, lässt einem ratlos und ohne Hoffnung zurück, präsentiert keine Lösungsansätze. Die Hauptbotschaft ist: Wir müssen, die Schweiz muss, sind dringend notwendig, die Bilanz ist vernichtend\\nEher negativ, wenig motivierend\\nEine kritische MM, aber auch ein Beispiel dafür, dass nicht jede MM konstruktiv sein kann. Hier geht es um ein Referendum, also um eine Nein-Kampagne gegen ein missratenes Gesetz.\\nSchweiz fällt im Rating zurück: Aber im Gegensatz zu anderen MMs, ist man eher zurückhaltend mit der Negativität.\\nSkandalisieren, Nein-Kamapagne\\nPointierte Verurteilung eines SR-Entscheids, sehr wertend (verharrt im 20. Jahrhundert, weigert sich, blockiert die Landwirschaft, politisiert an der Bevölkerung vorbei, ist völlig unverständlich). Schliesst mit der Aufforderung an den NR, der den Entscheid im Frühjahr dringend korrigieren muss. Zeigt wenig Kontext auf, präsentiert keine Lösung, ist sehr eindimensional (der böse Ständerat hat einfach krass falsch entschieden) - aber es bleibt unklar, warum und was wir den unter einer zukunftsfähigen Landwirtschaft verstehen. \\nVerurteilt Rolle der CH,  eindimensional, Botschaft: wir konsumieren zu viel und fördern so die Entwaldung, ohne Lösung, vermittelt dem Einzelnen  keine  Handlungsoptionen.  Wortwahl sehr fordernd (Massnamen müssen umfassend ergriffen werden, haben eine grosse Verantwortung, müssen ihre Risiken, alarmierenden Tempo...)\\nKritik, negative Komms\\neher nicht konstruktiv. Einige Punkte was man machen muss sind zwar aufgelistet, aber sind nicht sehr optimistisch.\\n\\nIst der folgende Text auf der Grundlage dieser Informationen konstruktiv oder nicht? Bitte erklären Sie warum. Bitte verwenden Sie für diese Klassifizierung keine Kontaktdaten:\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a489ba7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db88de9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d01816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b36e935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c21604eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = process_df(df)\n",
    "df = pdf.skim_cols(df, \n",
    "                   keep_cols = ['Inhalt','Konstruktiv (1= eher konstruktiv   0 = eher nicht konstruktiv ','Hinweis'],\n",
    "                   renamed_cols = ['content','label','reason'])\n",
    "df = pdf.clean_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c6116cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"../data/raw/Medienmitteilungen Export DE 20230822- Kriterien der Konstruktivität updated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f54e9ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ideal case would be to loop over entire Xy_train_series but can't due to limit on number of input tokens\n",
    "\n",
    "class presticker_compute():\n",
    "    def __init__(self, presticker, version, df:None, df2:None, label_map:None, question:None):\n",
    "        assert type(presticker)== str, f\"string presticker required, input type: {type(presticker)}\"\n",
    "        assert version in ['v1','v2'], f\"Version should be either v1 or v2\"\n",
    "        self.presticker = presticker\n",
    "        self.version = version\n",
    "        self.df = df\n",
    "        self.df2 = df2\n",
    "        self.label_map = label_map\n",
    "        self.question = question\n",
    "        \n",
    "    def get_presticker(self):\n",
    "        if self.version=='v1':\n",
    "            return self.presticker\n",
    "        if self.version=='v2':\n",
    "            assert type(self.df) ==pd.core.frame.DataFrame, f\"Pandas df required, input dtype: {type(self.df)}\"\n",
    "            assert type(self.df2) ==pd.core.frame.DataFrame, f\"Pandas df required, input dtype: {type(self.df2)}\"\n",
    "            assert type(self.label_map) == dict, f\"Dict required, input dtype: {type(self.label_map)}\"\n",
    "            assert type(self.question) == str, f\"str required, input dtype: {type(self.question)}\"\n",
    "            self.presticker = self.prestick_keypoints(self.df2, self.presticker)\n",
    "            self.presticker = self.prestick_reason(self.df, self.presticker, self.label_map)\n",
    "            self.presticker = self.prestick_question(self.presticker, self.question)\n",
    "            return self.presticker \n",
    "             \n",
    "    def prestick_keypoints(self, df, presticker):\n",
    "        for col in df.columns:\n",
    "            self.presticker += col\n",
    "            self.presticker += '\\n'\n",
    "            self.presticker += df.loc[:,col].str.cat(sep='\\n')\n",
    "            self.presticker += '\\n'\n",
    "        return self.presticker   \n",
    "\n",
    "    def prestick_reason(self, df, presticker, label_map):\n",
    "        for k,v in label_map.items():\n",
    "            self.presticker += v\n",
    "            self.presticker += \"\\n\"\n",
    "            self.presticker += df.loc[df['label']==k,'reason'].str.cat(sep='\\n')\n",
    "            self.presticker += \"\\n\"\n",
    "        return self.presticker    \n",
    "\n",
    "    def prestick_question(self, presticker, question):\n",
    "        self.presticker += \"\\n\"\n",
    "        self.presticker += question\n",
    "        self.presticker += \"\\n\"\n",
    "        return self.presticker            \n",
    "\n",
    "class poststicker_compute():\n",
    "    def __init__(self, poststicker, version:None):\n",
    "        assert type(poststicker)==str, f\"string poststicker required, input type: {type(poststicker)}\"\n",
    "        assert version in ['v1','v2'], f\"Version should be either v1 or v2\"\n",
    "        self.version = version\n",
    "        self.poststicker = poststicker\n",
    "     \n",
    "    def get_poststicker(self):\n",
    "        if self.version=='v1':\n",
    "            return self.poststicker\n",
    "        if self.version=='v2':\n",
    "            self.poststicker = ''\n",
    "            return self.poststicker\n",
    "    \n",
    "    \n",
    "label_map = {\n",
    "    0: \"Für den konstruktiven Text wurden folgende Punkte beachtet:\",\n",
    "    1: \"Bei nicht konstruktivem Text wurden folgende Punkte beachtet:\"\n",
    "}   \n",
    "\n",
    "#question = \"Ist der folgende Text auf der Grundlage dieser Informationen konstruktiv oder nicht? Bitte erklären Sie warum. Bitte verwenden Sie für diese Klassifizierung keine Kontaktdaten:\"    \n",
    "question = \"Im folgen sollst du diese Informationen nutzen, um Texte mit 0 (destruktiv/ nicht wirklich konsturktiv) oder 1 (konstruktiv) zu bewerten. Gebe außerdem eine Begründung. Bedenke, dass ein negativer aspekt immer zum Label 0 führt und dieser im Text überarbeitet werden sollte. Hier der Text:\"\n",
    "\n",
    "presticker  = presticker_compute('',\"v2\", df, df2, label_map, question).get_presticker()\n",
    "poststicker = poststicker_compute('',\"v2\").get_poststicker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466f0d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "presticker=''\n",
    "\n",
    "        def prestick_keypoints(self, df, presticker):\n",
    "            for col in df.columns:\n",
    "                presticker += col\n",
    "                presticker += '\\n'\n",
    "                presticker += df.loc[:,col].str.cat(sep='\\n')\n",
    "                presticker += '\\n'\n",
    "            return presticker   \n",
    "\n",
    "        def prestick_reason(df, presticker, label_map):\n",
    "            for k,v in label_map.items():\n",
    "                presticker += v\n",
    "                presticker += \"\\n\"\n",
    "                presticker += df.loc[df['label']==k,'reason'].str.cat(sep='\\n')\n",
    "                presticker += \"\\n\"\n",
    "\n",
    "            return presticker    \n",
    "\n",
    "\n",
    "        def prestick_question(presticker, question):\n",
    "            presticker += \"\\n\"\n",
    "            presticker += question\n",
    "            presticker += \"\\n\"\n",
    "            return presticker\n",
    "    \n",
    "label_map = {\n",
    "    0: \"Für den konstruktiven Text wurden folgende Punkte beachtet:\",\n",
    "    1: \"Bei nicht konstruktivem Text wurden folgende Punkte beachtet:\"\n",
    "}   \n",
    "\n",
    "question = \"Ist der folgende Text auf der Grundlage dieser Informationen konstruktiv oder nicht? Bitte erklären Sie warum. Bitte verwenden Sie für diese Klassifizierung keine Kontaktdaten:\"    \n",
    "        \n",
    "presticker = prestick_keypoints(df2, presticker)\n",
    "presticker = prestick_reason(df, presticker, label_map)\n",
    "presticker = prestick_question(presticker, question)\n",
    "presticker \n",
    "\n",
    "\n",
    "poststicker   = ''\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8f530a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a593b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b5133b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
